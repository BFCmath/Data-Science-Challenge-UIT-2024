{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Deep Learning for Multi-Label Learning - A Comprehensive Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This is just a summary of what i can understand from the original paper.\n",
    "\n",
    "Link paper: [here](https://arxiv.org/abs/2401.16549)\n",
    "\n",
    "Year: 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Depending on the goal, there are two primary tasks in \n",
    "MLL: multi-label classification (MLC) and multi-label ranking \n",
    "(MLR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "MLC constitutes the primary learning task, aiming \n",
    "to train a model that segregates the label set into relevant and \n",
    "irrelevant categories with relative to a query instance. On the \n",
    "other hand, MLR focuses on training a model to arrange the \n",
    "class labels based on their relevance to a query instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Currently, a \n",
    "predominant trend in MLC involves extensively incorporating \n",
    "DL techniques even for more challenging problems, such as \n",
    "Extreme MLC, imbalanced MLC, weakly \n",
    "supervised MLC, and MLC with missing labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## FUNDAMENTAL CONCEPTS OF MLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "MLL is founded on a dataset where instances are associated \n",
    "with several target variables or labels simultaneously. The main \n",
    "goal when working with such data is MLC, which aims to \n",
    "categorize the target variables into relevant and irrelevant \n",
    "groups for a specific instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Two traditional approaches exist for solving the MLL task: \n",
    "algorithm adaptation and problem transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Algorithm \n",
    "adaptation aims to modify or extend conventional learning \n",
    "methods learning to directly handle MLD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "On the other \n",
    "hand, problem transformation involves converting the MLC \n",
    "task into either one or multiple single-label classification tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The three most prominent \n",
    "methods from the problem transformation category include:\n",
    "+ label power-set (LP)\n",
    "+ binary relevance (BR)\n",
    "+ classifier chains (CC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The BR method breaks down the multi-label  problem into a series of independent binary \n",
    "problems. Subsequently, each binary problem is addressed \n",
    "using a traditional classifier.  Finally, the individual predictions \n",
    "are combined to get the subset of labels relevant to each test \n",
    "instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Although BR is relatively simple to implement, it is \n",
    "realized that BR ignores the possible relationship between \n",
    "labels (such as label dependency, cooccurrence, and \n",
    "correlation). To deal with the limitation of the BR method, the \n",
    "classifier chain (CC) was introduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This method \n",
    "interconnects binary classifiers in a sequential chain, where the \n",
    "predictions of preceding classifiers serve as features for \n",
    "subsequent classifiers. This allows the latter classifiers to \n",
    "leverage the correlation with earlier predictions to enhance the \n",
    "quality of their predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The approach of LP involves \n",
    "treating every distinct label combination as a class identifier, \n",
    "thereby converting the original MLD into a multi-class dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The classical \n",
    "approaches mentioned earlier prove ineffective in addressing \n",
    "these challenges. Recently, deep learning (DL) techniques have \n",
    "gained increased popularity across diverse disciplines, and \n",
    "MLC has been no exception to benefiting from the latest developments in DL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## DEEP LEARNING FOR MLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Neural Networks for MLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Deep Neural Networks for MLC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Deep neural networks (DNNs) have been employed to address \n",
    "MLC problems, and the simplest approach is to decompose the \n",
    "MLC problem into several sets of binary classification \n",
    "problems, one for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "However, this strategy encounters \n",
    "scalability issues, particularly when handling a substantial \n",
    "number of labels. Additionally, it considers missing labels as \n",
    "negatives, resulting in a performance decline, and ignores \n",
    "dependencies among labels, which is an important aspect of \n",
    "effective recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Therefore, a different approach that \n",
    "focuses on the use of label relationships needs to be explored. \n",
    "One such approach is BP-MLL (Backpropagation for Multi\n",
    "label Learning) which frames MLC problems as a neural \n",
    "network featuring numerous output nodes, with each node \n",
    "representing a distinct label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:300px\">\n",
    "    <img src=\"images/NNinMLC.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "One should consider the labels within $ùëå_i$ hold greater \n",
    "significance compared to those outside of $ùëå_i$.\n",
    "\n",
    " BP-MLL views \n",
    "each output node as a binary classification problem, and \n",
    "training is based on the classical BP algorithm, but in order to \n",
    "address the dependencies across labels, the new global error \n",
    "function is proposed that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "$$\n",
    "E = \\sum_{i=1}^{m} E_i = \\sum_{i=1}^{m} \\frac{1}{|\\mathcal{Y}_i||\\hat{\\mathcal{Y}}_i|} \\sum_{(k,l) \\in \\mathcal{Y}_i \\times \\hat{\\mathcal{Y}}_i} \\exp\\left( -\\left( C_k^i - C_l^i \\right) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Subsequently, correlations between label pairs are computed. \n",
    "The error function quantifies label output disparities. Learning \n",
    "entails minimizing this function by amplifying output values for \n",
    "labels belonging to training samples and reducing those for non\n",
    "members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The subsequent stage in \n",
    "attaining the MLC classifier involves identifying the label set \n",
    "associated with the input instance, which can be extracted from \n",
    "the output values of the neural network using the threshold \n",
    "function. If the value of the output neuron surpasses the \n",
    "threshold, the respective label is attributed to the input instance; \n",
    "otherwise, it is not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "An improvement to the BP-MLL method by modifying the global error function. This modified \n",
    "error function allows the threshold value to be determined \n",
    "automatically by adaptation during neural network learning \n",
    "instead of using an "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Furthermore, an author found the suboptimal \n",
    "performance of BP-MLL on textual datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In response to this \n",
    "limitation, thay explored the constraints of BP-MLL by \n",
    "substituting ranking loss minimization with the more \n",
    "commonly employed cross-entropy error function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The authors \n",
    "demonstrate the capability of a single hidden layer neural \n",
    "network to reach cutting-edge performance levels in extensive \n",
    "multi-label text classification assignments by leveraging the \n",
    "available techniques in DL, such as ReLUs, AdaGrad, and \n",
    "Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In a different study documented, a label-decision \n",
    "module was integrated into DNNs, resulting in the attainment \n",
    "of top-tier accuracy in multi-label image classification tasks. \n",
    "\n",
    "Building upon this framework, others introduced ML\n",
    "Net, a DNN designed for the MLC of biomedical texts. \n",
    "\n",
    "ML-Net \n",
    "incorporates the label‚Äìdecision module from, but it \n",
    "converts the framework from image processing to text \n",
    "classification. The ML-Net model integrates label prediction \n",
    "and decision-making within the same network, enabling the \n",
    "determination of output labels through a combination of label \n",
    "confidence scores and document context.\n",
    "\n",
    " Its objective is to \n",
    "reduce pairwise ranking errors among labels, allowing for end\n",
    "to-end training and prediction of the label set without requiring \n",
    "an additional step for determining output labels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Recently, other proposed a new loss for MLC, named ZLPR \n",
    "loss, to extend the application of DL in MLC. The authors \n",
    "extended the cross-entropy loss from the single-label \n",
    "classification, which is expressed in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "$$\n",
    "Loss_{z\\_lpr} = \\log\\left(1 + \\sum_{i \\in \\Omega_{pos}} e^{-s_i}\\right) + \\log\\left(1 + \\sum_{i \\in \\Omega_{neg}} e^{s_j}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In contrast to earlier ranking-based losses, ZLPR \n",
    "exhibits the capability to dynamically determine the number of \n",
    "target categories while enhancing a model's label-ranking \n",
    "proficiency.\n",
    "\n",
    " In comparison to certain binary losses, the ZLPR \n",
    "loss excels in capturing a more robust correlation of labels and \n",
    "elucidating the ranking relationship between negative and \n",
    "positive categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
